{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iICGjdkgU4WM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "RUzfWugMM5Gt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.rand((32,80))\n",
    "h = torch.rand((32,128))\n",
    "a = torch.einsum('bi,bj->bij', x, h)\n",
    "a = a.reshape((32,1,80,128))\n",
    "m = nn.Conv2d(1, 1, (5,3), stride=1,padding=1)\n",
    "m(a).shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ui4KfexlRjbY",
    "outputId": "fa08e952-c1be-4046-dabe-566039731e6a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 78, 128])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(torch.__version__)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDe1RFJ2P_3u",
    "outputId": "eb150f9c-a1bc-49d6-9ce4-acf0ac1d9827",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.12.1+cu113\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVDsLECKU4Wc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the line corresponding to your \"runtime type\" to run in Google Colab\n",
    "\n",
    "# CPU:\n",
    "# !pip install pydub torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# GPU:\n",
    "# !pip install pydub torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfDh30gHU4Wi",
    "outputId": "2596eabd-e2d7-4412-9040-ef9b4362dda0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h0EWmSbU4Wl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Importing the Dataset\n",
    "---------------------\n",
    "\n",
    "import cifar10 dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cixFpOH3DYa_",
    "outputId": "2e4ab8b9-f2c0-4368-febf-331137c8cf6f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4k6QLeQ_IYW0",
    "outputId": "1eee520b-4560-4cd6-fc6a-8a289cb5716e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([128, 3, 32, 32])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "IN_dim = 32*32\n",
    "T = 20"
   ],
   "metadata": {
    "id": "ATJJVqdB9w3_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sycRGkyU4YU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the Network\n",
    "------------------\n",
    "\n",
    "<!-- For this tutorial we will use a convolutional neural network to process\n",
    "the raw audio data. Usually more advanced transforms are applied to the\n",
    "audio data, however CNNs can be used to accurately process the raw data.\n",
    "The specific architecture is modeled after the M5 network architecture\n",
    "described in `this paper <https://arxiv.org/pdf/1610.00087.pdf>`__. An\n",
    "important aspect of models processing raw audio data is the receptive\n",
    "field of their first layer’s filters. Our model’s first filter is length\n",
    "80 so when processing audio sampled at 8kHz the receptive field is\n",
    "around 10ms (and at 4kHz, around 20 ms). This size is similar to speech\n",
    "processing applications that often use receptive fields ranging from\n",
    "20ms to 40ms. -->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6bJZrQMU4Ya",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Liquid time constant snn\n",
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "def create_exp_dir(path, scripts_to_save=None):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    print('Experiment dir : {}'.format(path))\n",
    "    if scripts_to_save is not None:\n",
    "        os.mkdir(os.path.join(path, 'scripts'))\n",
    "        for script in scripts_to_save:\n",
    "            dst_file = os.path.join(path, 'scripts', os.path.basename(script))\n",
    "            shutil.copyfile(script, dst_file)\n",
    "            \n",
    "\n",
    "def model_save(fn, model, criterion, optimizer):\n",
    "    with open(fn, 'wb') as f:\n",
    "        torch.save([model, criterion, optimizer], f)\n",
    "\n",
    "def model_load(fn):\n",
    "    with open(fn, 'rb') as f:\n",
    "        model, criterion, optimizer = torch.load(f)\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "def save_checkpoint(state, is_best, prefix, filename='_rec2_bias_checkpoint.pth.tar'):\n",
    "    print('saving at ', prefix+filename)\n",
    "    torch.save(state, prefix+filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(prefix+filename, prefix+ '_rec2_bias_model_best.pth.tar')\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.network.parameters() if p.requires_grad)\n",
    "\n",
    "###############################################################################################\n",
    "###############################    Define SNN layer   #########################################\n",
    "###############################################################################################\n",
    "\n",
    "b_j0 = .1  # neural threshold baseline\n",
    "R_m = 3  # membrane resistance\n",
    "dt = 1  \n",
    "gamma = .5  # gradient scale\n",
    "lens = 0.5\n",
    "\n",
    "def gaussian(x, mu=0., sigma=.5):\n",
    "    return torch.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / torch.sqrt(2 * torch.tensor(math.pi)) / sigma\n",
    "\n",
    "\n",
    "class ActFun_adp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):  # input = membrane potential- threshold\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(0).float()  # is firing ???\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  # approximate the gradients\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        # temp = abs(input) < lens\n",
    "        scale = 6.0\n",
    "        hight = .15\n",
    "        # temp = torch.exp(-(input**2)/(2*lens**2))/torch.sqrt(2*torch.tensor(math.pi))/lens\n",
    "        temp = gaussian(input, mu=0., sigma=lens) * (1. + hight) \\\n",
    "               - gaussian(input, mu=lens, sigma=scale * lens) * hight \\\n",
    "               - gaussian(input, mu=-lens, sigma=scale * lens) * hight\n",
    "        # temp =  gaussian(input, mu=0., sigma=lens)\n",
    "        return grad_input * temp.float() * gamma\n",
    "        # return grad_input\n",
    "\n",
    "\n",
    "act_fun_adp = ActFun_adp.apply\n",
    "\n",
    "def mem_update_adp(inputs, mem, spike, tau_adp,tau_m, b, dt=1, isAdapt=1):\n",
    "    alpha = tau_m\n",
    "    \n",
    "    ro = tau_adp\n",
    "\n",
    "    if isAdapt:\n",
    "        beta = 1.8\n",
    "    else:\n",
    "        beta = 0.\n",
    "\n",
    "    b = ro * b + (1 - ro) * spike\n",
    "    B = b_j0 + beta * b\n",
    "    \n",
    "\n",
    "\n",
    "    d_mem = -mem + inputs\n",
    "    mem = mem + d_mem*alpha\n",
    "    inputs_ = mem - B\n",
    "\n",
    "    spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n",
    "    mem = (1-spike)*mem\n",
    "\n",
    "    return mem, spike, B, b\n",
    "\n",
    "\n",
    "def output_Neuron(inputs, mem, tau_m, dt=1):\n",
    "    \"\"\"\n",
    "    The read out neuron is leaky integrator without spike\n",
    "    \"\"\"\n",
    "    d_mem = -mem  +  inputs\n",
    "    mem = mem+d_mem*tau_m\n",
    "    return mem\n",
    "###############################################################################################\n",
    "###############################################################################################\n",
    "###############################################################################################\n",
    "class SNN_rec_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,is_rec = False,is_LTC=True):\n",
    "        super(SNN_rec_cell, self).__init__()\n",
    "    \n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size \n",
    "        self.is_rec = is_rec\n",
    "        self.is_LTC = is_LTC\n",
    "\n",
    "        if is_rec:\n",
    "            self.layer1_x = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        else:\n",
    "            self.layer1_x = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # time-constant definiation and initilization \n",
    "        if is_LTC:\n",
    "            self.layer1_tauAdp = nn.Linear(2*hidden_size, hidden_size)\n",
    "            self.layer1_tauM = nn.Linear(2*hidden_size, hidden_size)\n",
    "            nn.init.xavier_uniform_(self.layer1_tauAdp.weight)\n",
    "            nn.init.xavier_uniform_(self.layer1_tauM.weight)\n",
    "        else:\n",
    "            self.tau_adp = nn.Parameter(torch.Tensor(hidden_size))\n",
    "            self.tau_m =nn.Parameter(torch.Tensor(hidden_size))\n",
    "            nn.init.normal_(self.tau_adp, 4.6,.1)\n",
    "            nn.init.normal_(self.tau_m, 3.,.1)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.layer1_x.weight)\n",
    "        \n",
    "\n",
    "    def forward(self, x_t, mem_t,spk_t,b_t):    \n",
    "        if self.is_rec:\n",
    "            dense_x = self.layer1_x(torch.cat((x_t,spk_t),dim=-1))\n",
    "        else:\n",
    "            dense_x = self.layer1_x(x_t)\n",
    "\n",
    "        if self.is_LTC:\n",
    "            tauM1 = self.act1(self.layer1_tauM(torch.cat((dense_x,mem_t),dim=-1)))\n",
    "            tauAdp1 = self.act1(self.layer1_tauAdp(torch.cat((dense_x,b_t),dim=-1)))\n",
    "        else:\n",
    "            tauM1 = self.act1(self.tau_m)\n",
    "            tauAdp1 = self.act2(self.tau_adp)\n",
    "        \n",
    "        mem_1,spk_1,_,b_1 = mem_update_adp(dense_x, mem=mem_t,spike=spk_t,\n",
    "                                        tau_adp=tauAdp1,tau_m=tauM1,b =b_t)\n",
    "\n",
    "        return mem_1,spk_1,b_1\n",
    "\n",
    "    def compute_output_size(self):\n",
    "        return [self.hidden_size]\n",
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,output_size,is_LTC=True):\n",
    "        super(SNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size \n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.rnn_name = 'SNN: is_LTC-'+str(is_LTC)\n",
    "\n",
    "        self.snn_a = SNN_rec_cell(input_size,hidden_size,False,is_LTC)\n",
    " \n",
    "        self.snn3 = SNN_rec_cell(hidden_size,hidden_size,False,is_LTC)\n",
    "        \n",
    "\n",
    "        self.layer3_x = nn.Linear(hidden_size,output_size,bias=True)\n",
    "        self.layer3_tauM = nn.Linear(output_size*2,output_size)\n",
    "        self.tau_m_o = nn.Parameter(torch.Tensor(output_size))\n",
    "\n",
    "        nn.init.constant_(self.tau_m_o, 20.)\n",
    "        # nn.init.constant_(self.tau_m_o, 0.)\n",
    "        nn.init.xavier_uniform_(self.layer3_x.weight)\n",
    "        nn.init.zeros_(self.layer3_tauM.weight)\n",
    "        self.act3 = nn.Sigmoid()\n",
    "        self.relu = nn.ELU()\n",
    "\n",
    "        self.dp1 = nn.Dropout(0.1)#.1\n",
    "        self.dp2 = nn.Dropout(0.1)\n",
    "        self.dp3 = nn.Dropout(0.1)\n",
    "        self.fr = 0\n",
    "        \n",
    "    def forward(self, inputs, h):\n",
    "        \n",
    "        \n",
    "        # outputs = []\n",
    "        hiddens = []\n",
    " \n",
    "        b,in_dim= inputs.shape\n",
    "        t = 1\n",
    "        for x_i in range(t):\n",
    "            x_down = inputs.reshape(b,self.input_size).float()\n",
    "\n",
    "            mem_1,spk_1,b_1 = self.snn_a(x_down, mem_t=h[0],spk_t=h[1],b_t = h[2])\n",
    "            mem_2,spk_2,b_2 = self.snn3(spk_1, mem_t=h[3],spk_t=h[4],b_t = h[5])\n",
    "\n",
    "            dense3_x = self.layer3_x(spk_2)\n",
    "            # tauM2 = self.act3(self.layer3_tauM(torch.cat((dense3_x, h[-2]),dim=-1)))\n",
    "            tauM2 = torch.exp(-1./(self.tau_m_o))\n",
    "            mem_out = output_Neuron(dense3_x,mem=h[-2],tau_m = tauM2)\n",
    "\n",
    "            out =mem_out\n",
    "            self.fr = self.fr+ spk_1.detach().cpu().numpy().mean()/2.\\\n",
    "                + spk_2.detach().cpu().numpy().mean()/2.\n",
    "\n",
    "        h = (mem_1,spk_1,b_1, \n",
    "            mem_2,spk_2,b_2, \n",
    "            mem_out,\n",
    "            out)\n",
    "\n",
    "        f_output = F.log_softmax(out, dim=1)\n",
    "        hiddens.append(h)\n",
    "\n",
    "        \n",
    "        final_state = h\n",
    "        return f_output, final_state, hiddens\n",
    "\n",
    "class SeqModel(nn.Module):\n",
    "    def __init__(self, ninp, nhid, nout,is_rec=True,is_LTC = True):\n",
    "\n",
    "        super(SeqModel, self).__init__()\n",
    "        self.nout = nout    # Should be the number of classes\n",
    "        self.nhid = nhid\n",
    "        self.is_rec = is_rec\n",
    "        self.is_LTC= is_LTC\n",
    "\n",
    "        self.network = SNN(input_size=ninp, hidden_size=nhid, output_size=nout)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "      \n",
    "        t = T\n",
    "        # print(inputs.shape) # L,B,d\n",
    "        outputs = []\n",
    "        for i in range(t):\n",
    "            f_output, hidden, hiddens= self.network.forward(inputs, hidden)\n",
    "            outputs.append(f_output)\n",
    "        return outputs, hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(bsz,self.nhid).uniform_(),\n",
    "                weight.new(bsz,self.nhid).zero_(),\n",
    "                weight.new(bsz,self.nhid).fill_(b_j0),\n",
    "                # layer 3\n",
    "                weight.new(bsz,self.nhid).uniform_(),\n",
    "                weight.new(bsz,self.nhid).zero_(),\n",
    "                weight.new(bsz,self.nhid).fill_(b_j0),\n",
    "                # layer out\n",
    "                weight.new(bsz,self.nout).zero_(),\n",
    "                # sum spike\n",
    "                weight.new(bsz,self.nout).zero_(),\n",
    "                )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FPTT function:"
   ],
   "metadata": {
    "id": "reBROJyycKef",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# fptt parameters\n",
    "alpha = .5\n",
    "beta = .5\n",
    "rho = 0."
   ],
   "metadata": {
    "id": "L1Gd6hay8Kkj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_stats_named_params( model ):\n",
    "    named_params = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        sm, lm, dm = param.detach().clone(), 0.0*param.detach().clone(), 0.0*param.detach().clone()\n",
    "        named_params[name] = (param, sm, lm, dm)\n",
    "    return named_params\n",
    "\n",
    "def post_optimizer_updates( named_params):\n",
    "    for name in named_params:\n",
    "        param, sm, lm, dm = named_params[name]\n",
    "        lm.data.add_( -alpha * (param - sm) )\n",
    "        sm.data.mul_( (1.0-beta) )\n",
    "        sm.data.add_( beta * param - (beta/alpha) * lm )\n",
    "\n",
    "def get_regularizer_named_params( named_params,  _lambda=1.0 ):\n",
    "    regularization = torch.zeros( [], device=device )\n",
    "    for name in named_params:\n",
    "        param, sm, lm, dm = named_params[name]\n",
    "        regularization += (rho-1.) * torch.sum( param * lm )\n",
    "        r_p = _lambda * 0.5 * alpha * torch.sum( torch.square(param - sm) )\n",
    "        regularization += r_p\n",
    "        # print(name,r_p)\n",
    "    return regularization \n",
    "\n",
    "def reset_named_params(named_params):\n",
    "    for name in named_params:\n",
    "        param, sm, lm, dm = named_params[name]\n",
    "        param.data.copy_(sm.data)"
   ],
   "metadata": {
    "id": "zLqvBu8lcKGQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test function"
   ],
   "metadata": {
    "id": "ju53O0_m8jYO",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # for data, target in test_loader:\n",
    "    for i ,(data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.mean(1).view(-1, 32*32 )\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            hidden = model.init_hidden(data.size(0))\n",
    "        \n",
    "            outputs, hidden= model(data, hidden) \n",
    "           \n",
    "            output = outputs[-1]\n",
    "            # output = torch.stack(outputs[-10:]).mean(dim=0)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').data.item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "           test_loss, correct, len(test_loader.dataset),\n",
    "           100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset)"
   ],
   "metadata": {
    "id": "6a0CYMDB8i12",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## training function"
   ],
   "metadata": {
    "id": "c2gyUrzh9Ali",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# training parameters\n",
    "K  = T # sequence length\n",
    "omega = int(T/K)\n",
    "clip = 1.\n",
    "log_interval = 100\n",
    "lr = 1e-3"
   ],
   "metadata": {
    "id": "2tsvt3Ny9AWv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def train(train_loader, n_classes, model, named_params):\n",
    "    global steps\n",
    "    global estimate_class_distribution\n",
    "\n",
    "    train_loss = 0\n",
    "    total_clf_loss = 0\n",
    "    total_regularizaton_loss = 0\n",
    "    total_oracle_loss = 0\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.mean(1).view(-1, 32*32)\n",
    "       \n",
    "        B = target.size()[0]\n",
    "\n",
    "        for p in range(K):\n",
    "\n",
    "            if p==0:\n",
    "                h = model.init_hidden(data.size(0))\n",
    "            elif p%omega==0:\n",
    "                h = tuple(v.detach() for v in h)\n",
    "\n",
    "            # print([p.shape for p in h])\n",
    "            if p<K-1:\n",
    "                if epoch < 10:\n",
    "                    oracle_prob = 0*estimate_class_distribution[target, p] + (1.0/n_classes)\n",
    "                else:\n",
    "                    oracle_prob = estimate_class_distribution[target, p]\n",
    "            else:\n",
    "                oracle_prob = F.one_hot(target,n_classes).float() \n",
    "\n",
    "            \n",
    "            o, h,hs = model.network.forward(data, h )\n",
    "\n",
    "            prob_out = F.softmax(h[-1], dim=1)\n",
    "            output = F.log_softmax(h[-1], dim=1) \n",
    "\n",
    "            \n",
    "            if p<K-1:\n",
    "                with torch.no_grad():\n",
    "                    filled_class = [0]*n_classes\n",
    "                    n_filled = 0\n",
    "                    for j in range(B):\n",
    "                        if n_filled==n_classes: break\n",
    "                        y = target[j].item()\n",
    "                        if filled_class[y] == 0 and (torch.argmax(prob_out[j]) != target[j]):\n",
    "                            filled_class[y] = 1\n",
    "                            estimate_class_distribution[y, p] = prob_out[j].detach()\n",
    "                            n_filled += 1\n",
    "            if p%omega==0 and p>0: \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                clf_loss = (p+1)/(K)*F.nll_loss(output, target)\n",
    "                # clf_loss = snr*F.cross_entropy(output, target,reduction='none')\n",
    "                # clf_loss = torch.mean(clf_loss)\n",
    "        \n",
    "                oracle_loss = 1.0 *torch.mean( -oracle_prob.to(device) * output )\n",
    "                # oracle_loss = (1 - (p+1)/(K)) *torch.mean(torch.mean( -oracle_prob.to(device) * output,axis=1)*snr)\n",
    "                    \n",
    "                regularizer = get_regularizer_named_params( named_params, _lambda=1.0 )      \n",
    "                loss = clf_loss  + regularizer  + oracle_loss\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                if clip > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                    \n",
    "                    \n",
    "                optimizer.step()\n",
    "                post_optimizer_updates( named_params)\n",
    "            \n",
    "                train_loss += loss.item()\n",
    "                total_clf_loss += clf_loss.item()\n",
    "                total_regularizaton_loss += regularizer #.item()\n",
    "                total_oracle_loss += oracle_loss.item()\n",
    "        \n",
    "        if batch_idx > 0 and batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tlr: {:.6f}\\tLoss: {:.6f}\\tOracle: \\\n",
    "                {:.6f}\\tClf: {:.6f}\\tReg: {:.6f}\\tFr: {:.6f}'.format(\n",
    "                   epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                   100. * batch_idx / len(train_loader), lr, train_loss / log_interval, \n",
    "                   total_oracle_loss / log_interval, \n",
    "                   total_clf_loss / log_interval, total_regularizaton_loss / log_interval, model.network.fr/T/log_interval))\n",
    "            # print(model.network.fr)\n",
    "            train_loss = 0\n",
    "            total_clf_loss = 0\n",
    "            total_regularizaton_loss = 0\n",
    "            total_oracle_loss = 0\n",
    "        model.network.fr = 0\n"
   ],
   "metadata": {
    "id": "lulnr6ue8x2N",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "N0aaWUv1TGXF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "n_classes = 10"
   ],
   "metadata": {
    "id": "NpB5aFfrCn4L",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = SeqModel(ninp=32*32,\n",
    "                    nhid=128,\n",
    "                    nout=n_classes)\n",
    "model.to(device)\n",
    "total_params = count_parameters(model)"
   ],
   "metadata": {
    "id": "6tuWZEmYCwoH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYFlr74NU4Y5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adamax(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)  # reduce the learning after 20 epochs by a factor of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Testing the Network\n",
    "--------------------------------\n",
    "\n",
    "Now let’s define a training function that will feed our training data\n",
    "into the model and perform the backward pass and optimization steps. For\n",
    "training, the loss we will use is the negative log-likelihood. The\n",
    "network will then be tested after each epoch to see how the accuracy\n",
    "varies during the training."
   ],
   "metadata": {
    "id": "xmwAqWtPFzMq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_loss, acc1 = test( model, test_loader )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_qyEdlAU5wH",
    "outputId": "a4848936-647d-4ac7-a172-1ccc2104c949",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.4017, Accuracy: 1015/10000 (10%)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 30\n",
    "named_params = get_stats_named_params( model )\n",
    "prefix ='save name'\n",
    "all_test_losses = []\n",
    "best_acc1 = 20\n",
    "\n",
    "estimate_class_distribution = torch.zeros(n_classes, T, n_classes, dtype=torch.float)\n",
    "for epoch in range(epochs):\n",
    "    train(train_loader, n_classes, model, named_params)   \n",
    "\n",
    "    reset_named_params(named_params)\n",
    "\n",
    "\n",
    "    test_loss, acc1 = test( model, test_loader )\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "        \n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "        \n",
    "    # save_checkpoint({\n",
    "    #         'epoch': epoch + 1,\n",
    "    #         'state_dict': model.state_dict(),\n",
    "    #         #'oracle_state_dict': oracle.state_dict(),\n",
    "    #         'best_acc1': best_acc1,\n",
    "    #         'optimizer' : optimizer.state_dict(),\n",
    "    #         #'oracle_optimizer' : oracle_optim.state_dict(),\n",
    "    #     }, is_best, prefix=prefix)\n",
    "\n",
    "    all_test_losses.append(test_loss)\n",
    "\n",
    "test_loss, acc1 = test( model, test_loader )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "id": "RDVycao8F1Sl",
    "outputId": "2ca0971a-734b-42dc-d58e-1f6e7204ff98",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 0 [12800/50000 (26%)]\tlr: 0.001000\tLoss: 20.646047\tOracle:                 4.928195\tClf: 20.644881\tReg: -4.927036\tFr: 0.003018\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tlr: 0.001000\tLoss: 18.534011\tOracle:                 5.167516\tClf: 17.435508\tReg: -4.069016\tFr: 0.003699\n",
      "Train Epoch: 0 [38400/50000 (77%)]\tlr: 0.001000\tLoss: 18.283499\tOracle:                 5.224163\tClf: 16.424660\tReg: -3.365325\tFr: 0.004021\n",
      "\n",
      "Test set: Average loss: 2.0389, Accuracy: 3133/10000 (31%)\n",
      "\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tlr: 0.001000\tLoss: 18.626490\tOracle:                 5.358927\tClf: 15.492237\tReg: -2.224671\tFr: 0.004993\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tlr: 0.001000\tLoss: 18.853267\tOracle:                 5.287042\tClf: 15.300009\tReg: -1.733781\tFr: 0.005380\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tlr: 0.001000\tLoss: 19.350520\tOracle:                 5.283876\tClf: 15.364701\tReg: -1.298056\tFr: 0.005514\n",
      "\n",
      "Test set: Average loss: 2.0536, Accuracy: 3098/10000 (31%)\n",
      "\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tlr: 0.001000\tLoss: 19.748925\tOracle:                 5.391272\tClf: 15.031743\tReg: -0.674091\tFr: 0.005701\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tlr: 0.001000\tLoss: 19.737730\tOracle:                 5.336314\tClf: 14.848295\tReg: -0.446879\tFr: 0.005873\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tlr: 0.001000\tLoss: 19.864869\tOracle:                 5.327528\tClf: 14.842420\tReg: -0.305079\tFr: 0.005940\n",
      "\n",
      "Test set: Average loss: 1.9994, Accuracy: 3205/10000 (32%)\n",
      "\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tlr: 0.001000\tLoss: 19.835554\tOracle:                 5.431863\tClf: 14.531162\tReg: -0.127472\tFr: 0.005945\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tlr: 0.001000\tLoss: 19.870646\tOracle:                 5.355837\tClf: 14.633548\tReg: -0.118738\tFr: 0.006163\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tlr: 0.001000\tLoss: 19.827012\tOracle:                 5.370610\tClf: 14.539110\tReg: -0.082708\tFr: 0.005990\n",
      "\n",
      "Test set: Average loss: 1.9959, Accuracy: 3258/10000 (33%)\n",
      "\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tlr: 0.001000\tLoss: 19.798571\tOracle:                 5.456059\tClf: 14.362280\tReg: -0.019767\tFr: 0.005926\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tlr: 0.001000\tLoss: 19.634449\tOracle:                 5.394036\tClf: 14.250626\tReg: -0.010213\tFr: 0.005994\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tlr: 0.001000\tLoss: 19.730420\tOracle:                 5.393643\tClf: 14.352275\tReg: -0.015499\tFr: 0.006027\n",
      "\n",
      "Test set: Average loss: 2.0083, Accuracy: 3287/10000 (33%)\n",
      "\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tlr: 0.001000\tLoss: 19.571361\tOracle:                 5.484393\tClf: 14.042711\tReg: 0.044257\tFr: 0.006092\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tlr: 0.001000\tLoss: 19.632131\tOracle:                 5.398315\tClf: 14.221026\tReg: 0.012790\tFr: 0.006152\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-48-64d3cdc45ef9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mestimate_class_distribution\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_classes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_classes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnamed_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0mreset_named_params\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnamed_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-43-62af5c56979d>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(train_loader, n_classes, model, named_params)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 71\u001B[0;31m                 \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     72\u001B[0m                 \u001B[0mpost_optimizer_updates\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mnamed_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m                 \u001B[0minstance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_step_count\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m                 \u001B[0mwrapped\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minstance\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0;31m# Note that the returned function here is no longer a bound method,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 113\u001B[0;31m                     \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    114\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamax.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    136\u001B[0m                    \u001B[0mweight_decay\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mweight_decay\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m                    \u001B[0mforeach\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mforeach\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 138\u001B[0;31m                    maximize=maximize)\n\u001B[0m\u001B[1;32m    139\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamax.py\u001B[0m in \u001B[0;36madamax\u001B[0;34m(params, grads, exp_avgs, exp_infs, state_steps, foreach, maximize, eps, beta1, beta2, lr, weight_decay)\u001B[0m\n\u001B[1;32m    186\u001B[0m          \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m          \u001B[0mweight_decay\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mweight_decay\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 188\u001B[0;31m          maximize=maximize)\n\u001B[0m\u001B[1;32m    189\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamax.py\u001B[0m in \u001B[0;36m_single_tensor_adamax\u001B[0;34m(params, grads, exp_avgs, exp_infs, state_steps, eps, beta1, beta2, lr, weight_decay, maximize)\u001B[0m\n\u001B[1;32m    221\u001B[0m             \u001B[0mexp_inf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmul_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbeta2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m             \u001B[0mgrad\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mabs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 223\u001B[0;31m         ], 0)\n\u001B[0m\u001B[1;32m    224\u001B[0m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mamax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnorm_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mexp_inf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}