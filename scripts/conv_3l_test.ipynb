{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa003518550>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import wandb\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from conv_net import *\n",
    "from conv_traintest import *\n",
    "from utils import *\n",
    "from FTTP import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# set seed\n",
    "torch.manual_seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# IMPORT DATASET\n",
    "###############################################################\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "testdata = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "\n",
    "# data loading\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# check data loading correctness\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    sample_data = data\n",
    "    print(data.shape)\n",
    "    _, c, h, w = data.shape\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN-conv + None\n",
      "output size 5408\n",
      "SNN-conv + None\n",
      "output size 4608\n",
      "SnnConvNet(\n",
      "  (dp): Dropout2d(p=0.2, inplace=False)\n",
      "  (h_layer): SnnLayer(\n",
      "    (fc_weights): Linear(in_features=784, out_features=784, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (conv1): SNNConvCell(\n",
      "    (conv_in): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "    (BN): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2): SNNConvCell(\n",
      "    (conv_in): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "    (BN): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_to_pop): Linear(in_features=4608, out_features=100, bias=True)\n",
      "  (pop_enc): SnnLayer(\n",
      "    (rec_w): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (pop_to_conv): Linear(in_features=100, out_features=4608, bias=True)\n",
      "  (deconv2): ConvTranspose2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (deconv1): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (output_layer): OutputLayer(\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "T = 20\n",
    "n_classes = 10\n",
    "\n",
    "###############################################################\n",
    "# DEFINE NETWORK\n",
    "###############################################################\n",
    "\n",
    "# set input and t param\n",
    "\n",
    "IN_dim = [c, h, w]\n",
    "hidden_channels = [8, 8, 8]\n",
    "kernel_size = [3, 3, 3]\n",
    "stride = [1, 1, 1]\n",
    "paddings = [0, 0, 0]\n",
    "pooling = None\n",
    "num_readout = 10\n",
    "conv_adp = True\n",
    "syn_curr_conv = False\n",
    "is_rec = [False, False, False]\n",
    "dp=0.2\n",
    "\n",
    "\n",
    "# define network\n",
    "model = SnnConvNet3Layer(IN_dim, hidden_channels, kernel_size, stride,\n",
    "                   paddings, n_classes, is_adapt_conv=conv_adp,\n",
    "                   syn_curr_conv=syn_curr_conv, dp_rate=dp, p_size=num_readout, \n",
    "                   pooling=pooling, is_rec=is_rec)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def model_result_dict_load(fn):\n",
    "    \"\"\"load tar file with saved model\n",
    "\n",
    "    Args:\n",
    "        fn (str): tar file name\n",
    "\n",
    "    Returns:\n",
    "        dict: dictornary containing saved results\n",
    "    \"\"\"\n",
    "    with open(fn, 'rb') as f:\n",
    "        dict = torch.load(f, map_location='cpu')\n",
    "    return dict\n",
    "\n",
    "exp_dir = '/home/lucy/spikingPC/results/Mar-06-2023/conv_fptt_ener1_rec_conv_2l_poisson2/'\n",
    "saved_dict = model_result_dict_load(exp_dir + 'onelayer_rec_best.pth.tar')\n",
    "\n",
    "model.load_state_dict(saved_dict['state_dict'])\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_names = []\n",
    "param_dict = {}\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        param_names.append(name)\n",
    "        param_dict[name] = param.detach().cpu().numpy()\n",
    "\n",
    "print(param_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weights = [x for x in param_names if ('weight' in x) and ('BN' not in x)][2:] # exclude h layer weights\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "connection_type = ['ff', 'ff', 'ff', 'rec', 'fb', 'fb', 'fb', 'ff', 'fb']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exci = []\n",
    "inhi = []\n",
    "\n",
    "for name in weights:\n",
    "    w = param_dict[name]\n",
    "    exci.append(((w>0)*w).mean())\n",
    "    inhi.append(-((w<0)*w).mean())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'weight': weights * 2,\n",
    "    'connection type': connection_type * 2,\n",
    "    'mean strength': exci + inhi,\n",
    "    'type': ['exci'] * len(exci) + ['inhi'] * len(inhi)\n",
    "})\n",
    "\n",
    "sns.catplot(\n",
    "    data=df, x=\"weight\", y=\"mean strength\", hue='type',\n",
    "    kind=\"bar\"\n",
    ")\n",
    "\n",
    "for i, label in enumerate(weights):\n",
    "    plt.annotate(connection_type[i], (i, df['mean strength'][i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.xticks(rotation=-45, ha='left')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max = np.max(np.abs(param_dict['pop_enc.rec_w.weight']))\n",
    "sns.heatmap(param_dict['pop_enc.rec_w.weight'], cmap='vlag', vmax=max, vmin=-max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.output_layer.tau_m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot your data\n",
    "for name, param in param_dict.items():\n",
    "    if 'tau_m' in name or 'tau_adp' in name:\n",
    "        sns.kdeplot(param.flatten(), label=name, ax=ax)\n",
    "\n",
    "# create legend outside plot area\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot your data\n",
    "for name, param in param_dict.items():\n",
    "    if ('conv_in' in name or 'deconv' in name) and 'weight' in name:\n",
    "        sns.kdeplot(param.flatten(), label=name, ax=ax)\n",
    "\n",
    "# create legend outside plot area\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot your data\n",
    "for name, param in param_dict.items():\n",
    "    if ('pop' in name and 'conv' in name) and 'weight' in name:\n",
    "        sns.kdeplot(param.flatten(), label=name, ax=ax)\n",
    "\n",
    "# plot init dist\n",
    "sns.kdeplot(nn.init.xavier_uniform_(torch.Tensor(model.conv_to_pop.weight.shape)).flatten(), label='init conv to pop')\n",
    "\n",
    "# create legend outside plot area\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.kdeplot(param_dict['pop_enc.rec_w.weight'].flatten())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# concentration of weights on 2d plane \n",
    "sns.heatmap((torch.abs(model.pop_to_conv.weight.detach().cpu())).sum(dim=1).reshape(model.conv2.output_shape).sum(dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k = model.conv1.conv_in.weight.detach().cpu().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, len(k), figsize=(25, 3))\n",
    "plt.title('conv 1 kernels')\n",
    "for i in range(len(k)):\n",
    "    abs_max = np.max(np.abs(k[i]))\n",
    "    sns.heatmap(k[i].squeeze(), ax=axs[i], vmax=abs_max, vmin=-abs_max, cmap='vlag')\n",
    "    axs[i].set_title('exci %.3f, inhi %.3f' % (((k[i]>0)*k[i]).sum(), ((k[i]<0)*k[i]).sum()))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = sample_data[2]\n",
    "conv1 = model.conv1.conv_in.weight.detach().cpu()\n",
    "conv1_bias = model.conv1.conv_in.bias.detach().cpu()\n",
    "\n",
    "conv2 = model.conv2.conv_in.weight.detach().cpu()\n",
    "conv2_bias = model.conv2.conv_in.bias.detach().cpu()\n",
    "\n",
    "feature1 = F.conv2d(img, conv1, bias=conv1_bias, stride=1, padding=0)\n",
    "feature2 = F.conv2d(feature1, conv2, bias=conv2_bias, stride=1, padding=0)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, len(conv1), figsize=(25, 6))\n",
    "plt.title('conv 1/2 feature maps')\n",
    "for i in range(len(conv1)):\n",
    "    sns.heatmap(feature1[i].squeeze(), ax=axs[0][i], cmap='gray')\n",
    "    sns.heatmap(feature2[i].squeeze(), ax=axs[1][i], cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deconv\n",
    "deconv1 = model.deconv1.weight.detach().cpu().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, len(deconv1), figsize=(25, 3))\n",
    "plt.title('deconv 1 kernels')\n",
    "for i in range(len(deconv1)):\n",
    "    abs_max = np.max(np.abs(deconv1[i]))\n",
    "    sns.heatmap(deconv1[i].squeeze(), ax=axs[i], vmax=abs_max, vmin=-abs_max, cmap='vlag')\n",
    "    axs[i].set_title('exci %.3f, inhi %.3f' % (((deconv1[i]>0)*deconv1[i]).sum(), ((deconv1[i]<0)*deconv1[i]).sum()))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k2 = model.conv2.conv_in.weight.detach().cpu().numpy()\n",
    "\n",
    "print(k2.shape)\n",
    "\n",
    "fig, axs = plt.subplots(1, len(k), figsize=(25, 3))\n",
    "plt.title('conv 1 kernels')\n",
    "for i in range(len(k2)):\n",
    "    sns.heatmap(k2[i].sum(axis=0), ax=axs[i], cmap='gray')\n",
    "    axs[i].set_title('exci %.3f, inhi %.3f' % (((k2[i]>0)*k2[i]).sum(), ((k2[i]<0)*k2[i]).sum()))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deconv2 = model.deconv2.weight.detach().cpu().numpy()\n",
    "\n",
    "print(deconv2.shape)\n",
    "\n",
    "fig, axs = plt.subplots(1, len(deconv2), figsize=(25, 3))\n",
    "plt.title('conv 1 kernels')\n",
    "for i in range(len(deconv2)):\n",
    "    sns.heatmap(deconv2[i].sum(axis=0), ax=axs[i], cmap='gray')\n",
    "    axs[i].set_title('exci %.3f, inhi %.3f' % (((deconv2[i]>0)*deconv2[i]).sum(), ((deconv2[i]<0)*deconv2[i]).sum()))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop_to_conv = model.pop_to_conv.weight.detach().cpu()\n",
    "conv_to_pop = model.conv_to_pop.weight.detach().cpu()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "sns.barplot(x=['exci', 'inhi'], y=[(pop_to_conv*(pop_to_conv>0)).numpy().mean(), -(pop_to_conv*(pop_to_conv<0)).numpy().mean()], ax=axs[0])\n",
    "sns.barplot(x=['exci', 'inhi'], y=[(conv_to_pop*(conv_to_pop>0)).numpy().mean(), -(conv_to_pop*(conv_to_pop<0)).numpy().mean()], ax=axs[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop_to_conv = model.pop_to_conv.weight.detach().cpu()\n",
    "deconv1 = model.deconv1.weight.detach().cpu()\n",
    "deconv1_bias = model.deconv1.bias.detach().cpu()\n",
    "deconv2 = model.deconv2.weight.detach().cpu()\n",
    "deconv2_bias = model.deconv2.bias.detach().cpu()\n",
    "deconv3 = model.deconv3.weight.detach().cpu()\n",
    "deconv3_bias = model.deconv3.bias.detach().cpu()\n",
    "\n",
    "# per pop encoding neuron detection of input in input space \n",
    "\n",
    "def visualise(index):\n",
    "    conv3_f = pop_to_conv[:, index*10:(index+1)*10].sum(dim=1).reshape(model.conv2.output_shape)\n",
    "    conv2_f = torch.nn.functional.conv_transpose2d(conv3_f, deconv3, bias=deconv3_bias, stride=1, padding=0, output_padding=0, groups=1, dilation=1)\n",
    "    conv1_f = torch.nn.functional.conv_transpose2d(conv2_f, deconv2, bias=deconv2_bias, stride=1, padding=0, output_padding=0, groups=1, dilation=1)\n",
    "    input = torch.nn.functional.conv_transpose2d(conv1_f, deconv1, bias=deconv1_bias, stride=1, padding=0, output_padding=0, groups=1, dilation=1)\n",
    "\n",
    "    return input\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 10, figsize=(35, 3))\n",
    "\n",
    "for i in range(10):\n",
    "    im = pop_to_conv[:, i*10:(i+1)*10].sum(dim=1).reshape(model.conv2.output_shape).mean(dim=0)\n",
    "    sns.heatmap(im.squeeze(), ax=axs[i], vmax=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get all hidden states\n",
    "def save_to_cpu(hidden_):\n",
    "    for i in range(len(hidden_)):\n",
    "        hidden_[i] = list(hidden_[i])\n",
    "        for j in range(len(hidden_[0])):\n",
    "            hidden_[i][j] = hidden_[i][j].cpu()\n",
    "\n",
    "    return hidden_\n",
    "\n",
    "def get_all_analysis_data(trained_model, test_loader, device, IN_dim, T, conv=None):\n",
    "    trained_model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    hiddens_all_ = []\n",
    "    preds_all_ = []  # predictions at all timesptes\n",
    "    data_all_ = []  # get transformed data \n",
    "\n",
    "    # for data, target in test_loader:\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        if i == 5:\n",
    "            break\n",
    "        data_all_.append(data.data)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        if conv is None:\n",
    "            data = data.view(-1, IN_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            trained_model.eval()\n",
    "            hidden = trained_model.init_hidden(data.size(0))\n",
    "\n",
    "            log_softmax_outputs, hidden = trained_model.inference(data, hidden, T)\n",
    "            hiddens_all_.append(save_to_cpu(hidden))\n",
    "\n",
    "            test_loss += F.nll_loss(log_softmax_outputs[-1], target, reduction='sum').data.item()\n",
    "\n",
    "            pred = log_softmax_outputs[-1].data.max(1, keepdim=True)[1]\n",
    "            preds_all_.append(pred)\n",
    "\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acc))\n",
    "\n",
    "    data_all_ = torch.stack(data_all_).reshape(i*batch_size, 28, 28)\n",
    "    preds_all_ = torch.stack(preds_all_).flatten().cpu().numpy()\n",
    "\n",
    "    return hiddens_all_, preds_all_, data_all_, test_acc\n",
    "\n",
    "\n",
    "hidden_all, preds_all, data_all, _ = get_all_analysis_data(model, test_loader, device, IN_dim, T, conv=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_states(hiddens_all_: list, idx: int, batch_size, T=20):\n",
    "    \"\"\"\n",
    "    get a particular internal state depending on index passed to hidden\n",
    "    :param hidden_dim_: the size of a state, eg. num of r or p neurons\n",
    "    :param T: total time steps\n",
    "    :param hiddens_all_: list containing hidden states of all batch and time steps during inference\n",
    "    :param idx: which index in h is taken out\n",
    "    :return: np array containing desired states\n",
    "    \"\"\"\n",
    "    all_states = []\n",
    "    for batch_idx in range(len(hiddens_all_)):  # iterate over batch\n",
    "        batch_ = []\n",
    "        for t in range(T):\n",
    "            seq_ = []\n",
    "            for b in range(batch_size):\n",
    "                seq_.append(hiddens_all_[batch_idx][t][idx][b].detach().cpu().numpy())\n",
    "            seq_ = np.stack(seq_)\n",
    "            batch_.append(seq_)\n",
    "        batch_ = np.stack(batch_)\n",
    "        all_states.append(batch_)\n",
    "\n",
    "    all_states = np.stack(all_states)\n",
    "\n",
    "    return all_states"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "h_spks = get_states(hidden_all, 1, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_samples = 5*200\n",
    "h_spks = h_spks.transpose(0, 2, 1, 3).reshape(n_samples, T, -1)\n",
    "h_spks.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv1_spks = get_states(hidden_all, 5, batch_size)\n",
    "conv2_spks = get_states(hidden_all, 9, batch_size)\n",
    "conv3_spks = get_states(hidden_all, 13, batch_size)\n",
    "\n",
    "print(conv1_spks.shape, conv2_spks.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv1_spks = conv1_spks.transpose(0, 2, 1, 3, 4, 5).reshape(n_samples, T, model.conv1.output_shape[0], model.conv1.output_shape[1], model.conv1.output_shape[2])\n",
    "conv2_spks = conv2_spks.transpose(0, 2, 1, 3, 4, 5).reshape(n_samples, T, model.conv2.output_shape[0], model.conv2.output_shape[1], model.conv2.output_shape[2])\n",
    "conv3_spks = conv3_spks.transpose(0, 2, 1, 3, 4, 5).reshape(n_samples, T, model.conv3.output_shape[0], model.conv3.output_shape[1], model.conv3.output_shape[2])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop_spks = get_states(hidden_all, 17, batch_size)\n",
    "pop_spks = pop_spks.transpose(0, 2, 1, 3).reshape(n_samples, T, -1)\n",
    "pop_spks.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_no = 3\n",
    "\n",
    "fig, axs = plt.subplots(5, 20, figsize=(100, 25))\n",
    "for t in range(T):\n",
    "    # h layer spk\n",
    "    sns.heatmap(h_spks[sample_no, t].reshape(28, 28), ax=axs[0, t])\n",
    "    axs[0, t].set_title('h spk')\n",
    "\n",
    "    # conv1\n",
    "    sns.heatmap(conv1_spks[sample_no, t].mean(axis=0), ax=axs[1, t], vmin=0, vmax=1)\n",
    "    axs[1, t].set_title('conv1 mean spk across channels')\n",
    "\n",
    "    # conv2\n",
    "    sns.heatmap(conv2_spks[sample_no, t].mean(axis=0), ax=axs[2, t], vmin=0, vmax=1)\n",
    "    axs[2, t].set_title('conv2 mean spk across channels')\n",
    "\n",
    "    # conv3\n",
    "    sns.heatmap(conv3_spks[sample_no, t].mean(axis=0), ax=axs[3, t], vmin=0, vmax=1)\n",
    "    axs[3, t].set_title('conv3 mean spk across channels')\n",
    "\n",
    "    # pop\n",
    "    sns.heatmap(pop_spks[sample_no, t].reshape(10, 10), ax=axs[4, t], vmin=0, vmax=1)\n",
    "    axs[4, t].set_title('pop spk')\n",
    "\n",
    "plt.savefig(exp_dir + 'spk exp seq.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# top down sig\n",
    "fig, axs = plt.subplots(5, 20, figsize=(100, 25))\n",
    "for t in range(T):\n",
    "    # h layer spk\n",
    "    inhi1 = torch.conv_transpose2d(torch.tensor(conv1_spks[sample_no, t]), model.deconv1.weight.detach().cpu(), model.deconv1.bias.detach().cpu(), stride=1, padding=1)\n",
    "    sns.heatmap(inhi1.squeeze(), ax=axs[0, t], vmax=2, vmin=-2, cmap='vlag')\n",
    "    axs[0, t].set_title('h fb')\n",
    "\n",
    "    # conv1\n",
    "    inhi2 = torch.conv_transpose2d(torch.tensor(conv2_spks[sample_no, t]), model.deconv2.weight.detach().cpu(), model.deconv2.bias.detach().cpu(), stride=1, padding=1)\n",
    "    sns.heatmap(inhi2.mean(axis=0), ax=axs[1, t], vmax=2, vmin=-2, cmap='vlag')\n",
    "    axs[1, t].set_title('conv1 fb')\n",
    "\n",
    "    # conv2\n",
    "    inhi3 = torch.conv_transpose2d(torch.tensor(conv3_spks[sample_no, t]), model.deconv3.weight.detach().cpu(), model.deconv3.bias.detach().cpu(), stride=1, padding=1)\n",
    "    sns.heatmap(inhi3.mean(axis=0), ax=axs[2, t], vmax=2, vmin=-2, cmap='vlag')\n",
    "    axs[2, t].set_title('conv2 fb')\n",
    "\n",
    "    # conv3\n",
    "    inhi3 = (pop_to_conv @ pop_spks[sample_no, t]).reshape(model.conv3.output_shape[0], model.conv3.output_shape[1], model.conv3.output_shape[2])\n",
    "    sns.heatmap(inhi3.mean(axis=0), ax=axs[3, t], vmin=-0.1, vmax=0.1, cmap='vlag')\n",
    "    axs[3, t].set_title('conv3 fb')\n",
    "\n",
    "    # pop\n",
    "    rec = model.pop_enc.rec_w.weight.detach().cpu().numpy() @ pop_spks[sample_no, t]\n",
    "    sns.heatmap(rec.reshape(10, 10), ax=axs[4, t], vmax=1, vmin=-1, cmap='vlag')\n",
    "    axs[4, t].set_title('pop spk')\n",
    "\n",
    "plt.savefig(exp_dir + str(sample_no) + 'top down sig.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1a9c8db136bcb25071b4037caa9dc5bb0f6af28abc90ee0089151c846e2c6f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}